{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4cfc7b7",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef071c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6719287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName('Clustering_seed').\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9194b88",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b6a5a",
   "metadata": {},
   "source": [
    "### Importing the Seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc658592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- area: double (nullable = true)\n",
      " |-- perimeter: double (nullable = true)\n",
      " |-- compactness: double (nullable = true)\n",
      " |-- length_of_kernel: double (nullable = true)\n",
      " |-- width_of_kernel: double (nullable = true)\n",
      " |-- asymmetry_coefficient: double (nullable = true)\n",
      " |-- length_of_groove: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('seeds_dataset.csv', header = True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174ac93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.26\n",
      "14.84\n",
      "0.871\n",
      "5.763\n",
      "3.312\n",
      "2.221\n",
      "5.22\n"
     ]
    }
   ],
   "source": [
    "for item in df.head(1)[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db099f",
   "metadata": {},
   "source": [
    "### Vectorizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d119965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "data = VectorAssembler(inputCols=df.columns, outputCol='features').transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11ba787",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select('features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43980752",
   "metadata": {},
   "source": [
    "### Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e21015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features').fit(data)\n",
    "data = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d6eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[15.26,14.84,0.87...|[5.24452795332028...|\n",
      "|[14.88,14.57,0.88...|[5.11393027165175...|\n",
      "|[14.29,14.09,0.90...|[4.91116018695588...|\n",
      "|[13.84,13.94,0.89...|[4.75650503761158...|\n",
      "|[16.14,14.99,0.90...|[5.54696468981581...|\n",
      "|[14.38,14.21,0.89...|[4.94209121682475...|\n",
      "|[14.69,14.49,0.87...|[5.04863143081749...|\n",
      "|[14.11,14.1,0.891...|[4.84929812721816...|\n",
      "|[16.63,15.46,0.87...|[5.71536696354628...|\n",
      "|[16.44,15.25,0.88...|[5.65006812271202...|\n",
      "|[15.26,14.85,0.86...|[5.24452795332028...|\n",
      "|[14.03,14.16,0.87...|[4.82180387844584...|\n",
      "|[13.89,14.02,0.88...|[4.77368894309428...|\n",
      "|[13.78,14.06,0.87...|[4.73588435103234...|\n",
      "|[13.74,14.05,0.87...|[4.72213722664617...|\n",
      "|[14.59,14.28,0.89...|[5.01426361985209...|\n",
      "|[13.99,13.83,0.91...|[4.80805675405968...|\n",
      "|[15.69,14.75,0.90...|[5.39230954047151...|\n",
      "|[14.7,14.21,0.915...|[5.05206821191403...|\n",
      "|[12.72,13.57,0.86...|[4.37158555479908...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9033a4",
   "metadata": {},
   "source": [
    "## Fitting and predicting with KMeans Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988a69a",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf74600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSSE: 428.608\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "model = KMeans(k=3, featuresCol='scaled_features').setSeed(42).fit(data)\n",
    "print('WSSE: {:.3f}'.format(model.summary.trainingCost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840da3aa",
   "metadata": {},
   "source": [
    "### Predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9cc7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|   71|\n",
      "|         1|   67|\n",
      "|         2|   72|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(data)\n",
    "prediction.groupBy('prediction').count().orderBy('prediction').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
