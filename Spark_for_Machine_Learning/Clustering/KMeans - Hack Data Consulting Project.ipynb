{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5958bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ec4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName('Hack_Project').\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c70b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Session_Connection_Time: double (nullable = true)\n",
      " |-- Bytes Transferred: double (nullable = true)\n",
      " |-- Kali_Trace_Used: integer (nullable = true)\n",
      " |-- Servers_Corrupted: double (nullable = true)\n",
      " |-- Pages_Corrupted: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- WPM_Typing_Speed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('hack_data.csv', header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9194572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Location|count|\n",
      "+--------------------+-----+\n",
      "|            Anguilla|    1|\n",
      "|            Paraguay|    2|\n",
      "|               Macao|    2|\n",
      "|Heard Island and ...|    2|\n",
      "|               Yemen|    1|\n",
      "|             Tokelau|    2|\n",
      "|              Sweden|    3|\n",
      "|French Southern T...|    3|\n",
      "|            Kiribati|    1|\n",
      "|              Guyana|    2|\n",
      "|         Philippines|    3|\n",
      "|            Malaysia|    2|\n",
      "|           Singapore|    1|\n",
      "|United States Vir...|    6|\n",
      "|              Turkey|    1|\n",
      "|      Western Sahara|    2|\n",
      "|              Malawi|    2|\n",
      "|                Iraq|    3|\n",
      "|Northern Mariana ...|    3|\n",
      "|             Germany|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Location').count().show() # Possibly Hackers used VPN, therefore Location data is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff5be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Session_Connection_Time',\n",
       " 'Bytes Transferred',\n",
       " 'Kali_Trace_Used',\n",
       " 'Servers_Corrupted',\n",
       " 'Pages_Corrupted',\n",
       " 'WPM_Typing_Speed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop('Location')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b7bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.56785108466505...|\n",
      "|[1.41962771166263...|\n",
      "|[2.20042295307707...|\n",
      "|[0.14196277116626...|\n",
      "|[1.41962771166263...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "assembler = VectorAssembler(inputCols=data.columns, outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "\n",
    "scaler = StandardScaler(inputCol='features', outputCol='Scaled_feats').fit(data)\n",
    "data = scaler.transform(data)\n",
    "data = data.select('Scaled_feats')\n",
    "data = data.withColumnRenamed('Scaled_feats', 'features')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0203bbf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WSSE with k = 2: 601.771\n",
      "\n",
      "Predictions with k = 2\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|  167|\n",
      "|         1|  167|\n",
      "+----------+-----+\n",
      "\n",
      "--------------------------------------------------\n",
      "Model WSSE with k = 3: 434.755\n",
      "\n",
      "Predictions with k = 3\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|  167|\n",
      "|         1|   88|\n",
      "|         2|   79|\n",
      "+----------+-----+\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "for k in [2, 3]:\n",
    "    model = KMeans(k=k).setSeed(42).fit(data)\n",
    "    print('Model WSSE with k = {}: {:.3f}'.format(k, model.summary.trainingCost))\n",
    "    predictions = model.transform(data)\n",
    "    print('\\nPredictions with k = {}'.format(k))\n",
    "    predictions.groupBy('prediction').count().orderBy('prediction').show()\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f7477",
   "metadata": {},
   "source": [
    "**Conclusion:** Forensic Engineer expects a equal share of task between hackers. For example, if there are 120 tasks, there would be 60 tasks each for 2 hackers and there would be 40 tasks each for 3 hackers. The results of $k = 2$ confirms that expectation and the conclusion is that there were 2 hackers during the attack. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
