{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be14628",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f34a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd877111",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName('Dog_Food').\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee02fb1",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde670c9",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9cf10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+\n",
      "|  A|  B|   C|  D|Spoiled|\n",
      "+---+---+----+---+-------+\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "|  5|  6|12.0|  7|    1.0|\n",
      "|  6|  2|13.0|  6|    1.0|\n",
      "|  4|  2|12.0|  1|    1.0|\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "+---+---+----+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('dog_food.csv', inferSchema=True, header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4021d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a780717",
   "metadata": {},
   "source": [
    "### Encoding the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d88639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol='Spoiled', outputCol='label').fit(df)\n",
    "output = indexer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00dddbb",
   "metadata": {},
   "source": [
    "### Preparing the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4702a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[4.0,2.0,12.0,3.0...|  1.0|\n",
      "|[5.0,6.0,12.0,7.0...|  1.0|\n",
      "|[6.0,2.0,13.0,6.0...|  1.0|\n",
      "|[4.0,2.0,12.0,1.0...|  1.0|\n",
      "|[4.0,2.0,12.0,3.0...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=output.columns[:-1], outputCol='features').transform(output)\n",
    "data = assembler.select('features', 'label')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97ff15",
   "metadata": {},
   "source": [
    "## Fitting and predicting with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b738510c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.0013, 1: 0.0023, 2: 0.3516, 3: 0.0014, 4: 0.6435})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "model = RandomForestClassifier(numTrees=150).fit(data)\n",
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625277c8",
   "metadata": {},
   "source": [
    "Highest important feature is *D* with *65%*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
